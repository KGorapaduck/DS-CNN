import pyaudio
import numpy as np
import tensorflow as tf
from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio
import collections
import os
import sys

# --- 1. íŒŒë¼ë¯¸í„° ì„¤ì • ---
SAMPLE_RATE = 16000
CHUNK_DURATION_MS = 250
CHUNK_SIZE = int(SAMPLE_RATE * CHUNK_DURATION_MS / 1000)
WINDOW_SIZE_MS = 40.0
WINDOW_STRIDE_MS = 20.0
DCT_COEFFICIENT_COUNT = 10
CLIP_DURATION_SAMPLES = SAMPLE_RATE

LABELS = ['_silence_', '_unknown_', 'quiz', 'understand']
CHECKPOINT_DIR = "./work/ds_cnn_korean/best"

# --- 2. TF ì„¸ì…˜ ë° ê·¸ë˜í”„ êµ¬ì¶• ---
tf.reset_default_graph()
sess = tf.InteractiveSession()

# ì…ë ¥ í”Œë ˆì´ìŠ¤í™€ë”
wav_placeholder = tf.placeholder(tf.float32, [CLIP_DURATION_SAMPLES, 1])

# MFCC ì „ì²˜ë¦¬ ê·¸ë˜í”„
spectrogram = contrib_audio.audio_spectrogram(
    wav_placeholder,
    window_size=int(SAMPLE_RATE * WINDOW_SIZE_MS / 1000),
    stride=int(SAMPLE_RATE * WINDOW_STRIDE_MS / 1000),
    magnitude_squared=True)
mfcc_op = contrib_audio.mfcc(
    spectrogram,
    SAMPLE_RATE,
    dct_coefficient_count=DCT_COEFFICIENT_COUNT)
mfcc_flatten = tf.reshape(mfcc_op, [1, -1]) # [1, 490]

# --- 3. DS-CNN ì•„í‚¤í…ì²˜ ì¬êµ¬ì¶• (ì²´í¬í¬ì¸íŠ¸ íŒŒë¼ë¯¸í„° ë¡œë”©ìš©) ---
# NOTE: To load a .ckpt without freezing, we must recreate the exact same network graph.
# Since importing models.py might be tricky dynamically, we can use the original project's models module.
# 2. Frozen Graph(.pb) ë¡œë“œ
graph_def = tf.compat.v1.GraphDef()
with tf.io.gfile.GFile("work/ds_cnn_korean_frozen.pb", 'rb') as f:
    graph_def.ParseFromString(f.read())
    
# í˜„ì¬ Graphì— ë¡œë“œí•œ ë…¸ë“œ ì¶”ê°€
tf.import_graph_def(graph_def, name='frozen_model')

# Graph ë‚´ í…ì„œ(Tensor) ê°€ì ¸ì˜¤ê¸°
model_graph = tf.compat.v1.get_default_graph()
fingerprint_input = model_graph.get_tensor_by_name("frozen_model/Reshape:0")
probabilities_op = model_graph.get_tensor_by_name("frozen_model/labels_softmax:0")


# --- 4. ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë° ì„¸íŒ… ---
window_history = collections.deque(maxlen=2)
suppression_counter = 0
SUPPRESSION_PULL_DOWN = 6

audio_buffer = np.zeros(CLIP_DURATION_SAMPLES, dtype=np.float32)

p = pyaudio.PyAudio()
stream = p.open(format=pyaudio.paInt16,
                channels=1,
                rate=SAMPLE_RATE,
                input=True,
                frames_per_buffer=CHUNK_SIZE)

print("\n==== ğŸ¤ ì‹¤ì‹œê°„ ë§ˆì´í¬ KWS(í•œêµ­ì–´ .ckpt ì¶”ë¡ ) ì‹œì‘ ====")
print("('í€´ì¦ˆ' ë˜ëŠ” 'ì´í•´í•˜ì…¨ë‚˜ìš”'ë¥¼ ë§í•´ë³´ì„¸ìš”!)")
print("=========================================================")

try:
    while True:
        data = stream.read(CHUNK_SIZE, exception_on_overflow=False)
        audio_chunk = np.frombuffer(data, dtype=np.int16).astype(np.float32) / 32768.0
        volume = np.max(np.abs(audio_chunk))
        
        audio_buffer = np.roll(audio_buffer, -CHUNK_SIZE)
        audio_buffer[-CHUNK_SIZE:] = audio_chunk
        
        # 1. 1ì´ˆ ì˜¤ë””ì˜¤ -> MFCC Feature ì¶”ì¶œ
        mfcc_feat = sess.run(mfcc_flatten, feed_dict={wav_placeholder: audio_buffer.reshape(-1, 1)})
        
        # 2. MFCC -> Logits -> Probabilities (using the restored DS-CNN)
        probs = sess.run(probabilities_op, feed_dict={fingerprint_input: mfcc_feat})[0]
        
        window_history.append(probs)
        
        if len(window_history) == window_history.maxlen:
            smoothed_output = np.mean(window_history, axis=0)
            top_index = np.argmax(smoothed_output)
            top_score = smoothed_output[top_index]
            prediction = LABELS[top_index]
            
            if suppression_counter > 0:
                suppression_counter -= 1
                msg = f"  (ê°ì§€ ë³´ë¥˜ ì¤‘... ë³¼ë¥¨: {volume:.2f})           "
                print(msg, end='\r', flush=True)
                continue
            
            if volume < 0.02:
                prediction = '_silence_'
            
            # íƒ€ê²Ÿ í•œêµ­ì–´ í¬ì°© í™•ì¸ (AIHub ëŒ€ê·œëª¨ ê²€ì¦ ê¸°ë°˜ ìµœì  Threshold ì ìš©)
            # 'quiz' í‰ê°€ Median: 0.98 -> ë³´ìˆ˜ì ìœ¼ë¡œ 0.6 ì„¤ì •
            # 'understand' í‰ê°€ Median: 0.83 (Lowest 0.007 ë¶„ì‚° ì‹¬í•¨) -> ë¯¼ê°í•˜ê²Œ 0.3 ì„¤ì •
            if (prediction == 'quiz' and top_score >= 0.6) or (prediction == 'understand' and top_score >= 0.3):
                print(f"ğŸ”¥ í¬ì°©ë¨: '{prediction}' (ì‹ ë¢°ë„: {top_score*100:.1f}%, ë³¼ë¥¨: {volume:.2f})")
                suppression_counter = SUPPRESSION_PULL_DOWN
            else:
                msg = f"  ({prediction}: {top_score*100:.1f}%, ë³¼ë¥¨: {volume:.2f})           "
                print(msg, end='\r', flush=True)

except KeyboardInterrupt:
    print("\n==== ğŸ›‘ ë§ˆì´í¬ KWS ì¢…ë£Œ ====")
finally:
    stream.stop_stream()
    stream.close()
    p.terminate()
    sess.close()
