import socket
import numpy as np
import tensorflow as tf
from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio
import collections
import time
import os

# --- 1. íŒŒë¼ë¯¸í„° ë° í†µì‹  ì„¤ì • ---
HOST = '0.0.0.0'  # ëª¨ë“  ì¸í„°í˜ì´ìŠ¤ì—ì„œ ì ‘ì† í—ˆìš©
PORT = 9999       # í¬íŠ¸ ë²ˆí˜¸

SAMPLE_RATE = 16000
CHUNK_DURATION_MS = 250
CHUNK_SIZE = int(SAMPLE_RATE * CHUNK_DURATION_MS / 1000)  # 4000 samples
WINDOW_SIZE_MS = 40.0
WINDOW_STRIDE_MS = 20.0
DCT_COEFFICIENT_COUNT = 10
CLIP_DURATION_SAMPLES = SAMPLE_RATE

LABELS = ['_silence_', '_unknown_', 'quiz', 'understand']
PB_MODEL_PATH = "work/ds_cnn_korean_frozen.pb"

if not os.path.exists(PB_MODEL_PATH):
    PB_MODEL_PATH = "ds_cnn_korean_frozen.pb"

if not os.path.exists(PB_MODEL_PATH):
    print(f"âŒ ì˜¤ë¥˜: '{PB_MODEL_PATH}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
    exit(1)

# --- 2. TF ì„¸ì…˜ ë° ê·¸ë˜í”„ êµ¬ì¶• ---
tf.reset_default_graph()
sess = tf.compat.v1.InteractiveSession()
wav_placeholder = tf.placeholder(tf.float32, [CLIP_DURATION_SAMPLES, 1])

# MFCC ì¶”ì¶œ ê·¸ë˜í”„
spectrogram = contrib_audio.audio_spectrogram(
    wav_placeholder,
    window_size=int(SAMPLE_RATE * WINDOW_SIZE_MS / 1000),
    stride=int(SAMPLE_RATE * WINDOW_STRIDE_MS / 1000),
    magnitude_squared=True)
mfcc_op = contrib_audio.mfcc(
    spectrogram,
    SAMPLE_RATE,
    dct_coefficient_count=DCT_COEFFICIENT_COUNT)
mfcc_flatten = tf.reshape(mfcc_op, [1, -1])

# --- 3. Frozen Graph ë¡œë“œ ---
graph_def = tf.compat.v1.GraphDef()
with tf.io.gfile.GFile(PB_MODEL_PATH, 'rb') as f:
    graph_def.ParseFromString(f.read())
tf.import_graph_def(graph_def, name='frozen_model')

model_graph = tf.compat.v1.get_default_graph()
fingerprint_input = model_graph.get_tensor_by_name("frozen_model/Reshape:0")
probabilities_op = model_graph.get_tensor_by_name("frozen_model/labels_softmax:0")

# --- 4. ì•ˆì •ì„± ë¡œì§ ì„¸íŒ… ---
window_history = collections.deque(maxlen=2)
suppression_counter = 0                       
SUPPRESSION_PULL_DOWN = 6                     
audio_buffer = np.zeros(CLIP_DURATION_SAMPLES, dtype=np.float32)

def recvall(sock, n):
    """ì§€ì •ëœ ë°”ì´íŠ¸ ìˆ˜(n)ë§Œí¼ ì†Œì¼“ì—ì„œ ì™„ì „íˆ ì½ì–´ì˜¤ëŠ” í—¬í¼ í•¨ìˆ˜"""
    data = bytearray()
    while len(data) < n:
        packet = sock.recv(n - len(data))
        if not packet:
            return None
        data.extend(packet)
    return data

# --- 5. ì†Œì¼“ ì„œë²„ êµ¬ë™ ---
server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
server_socket.bind((HOST, PORT))
server_socket.listen(1)

print(f"\n==== ğŸ“¡ ì†Œì¼“ ì„œë²„ ì‹œì‘ (í¬íŠ¸: {PORT}) ====")
print(f"ëª¨ë¸ íŒŒì¼: {PB_MODEL_PATH}")
print("PC(í´ë¼ì´ì–¸íŠ¸)ì˜ ì—°ê²°ì„ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤...\n")

while True:
    client_socket, addr = server_socket.accept()
    print(f"\nâœ… í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨: {addr}")
    
    # ì—°ê²°ë  ë•Œë§ˆë‹¤ ë²„í¼ ì´ˆê¸°í™”
    audio_buffer = np.zeros(CLIP_DURATION_SAMPLES, dtype=np.float32)
    window_history.clear()
    suppression_counter = 0
    
    try:
        while True:
            # 16bit(2 bytes) * 4000 samples = 8000 bytes
            raw_data = recvall(client_socket, CHUNK_SIZE * 2)
            
            if not raw_data:
                print(f"í´ë¼ì´ì–¸íŠ¸({addr}) ì—°ê²° ì¢…ë£Œ")
                break
            
            # Int16 -> Float32 [-1.0, 1.0] ì •ê·œí™”
            audio_chunk_int16 = np.frombuffer(raw_data, dtype=np.int16)
            audio_chunk = audio_chunk_int16.astype(np.float32) / 32768.0
            volume = np.max(np.abs(audio_chunk))
            
            # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°
            audio_buffer = np.roll(audio_buffer, -CHUNK_SIZE)
            audio_buffer[-CHUNK_SIZE:] = audio_chunk
            
            # MFCC ë³€í™˜ ë° ì¶”ë¡ 
            mfcc_feat = sess.run(mfcc_flatten, feed_dict={wav_placeholder: audio_buffer.reshape(-1, 1)})
            probs = sess.run(probabilities_op, feed_dict={fingerprint_input: mfcc_feat})[0]
            
            window_history.append(probs)
            
            if len(window_history) == window_history.maxlen:
                smoothed_output = np.mean(window_history, axis=0)
                top_index = np.argmax(smoothed_output)
                top_score = smoothed_output[top_index]
                prediction = LABELS[top_index]
                
                if suppression_counter > 0:
                    suppression_counter -= 1
                    msg = f"  (ê°ì§€ ë³´ë¥˜ ì¤‘... ë³¼ë¥¨: {volume:.2f})"
                    print(msg.ljust(50), end='\r', flush=True)
                    continue
                
                if volume < 0.02:
                    prediction = '_silence_'
                
                if (prediction == 'quiz' and top_score >= 0.6) or (prediction == 'understand' and top_score >= 0.3):
                    print(f"ğŸ”¥ í¬ì°©ë¨: '{prediction}' (ì‹ ë¢°ë„: {top_score*100:.1f}%, ë³¼ë¥¨: {volume:.2f})")
                    
                    # í´ë¼ì´ì–¸íŠ¸ë¡œ íŠ¸ë¦¬ê±° ì´ë²¤íŠ¸ ì „ì†¡ (newline í¬í•¨)
                    send_msg = f"TRIGGER_{prediction.upper()}\n"
                    client_socket.sendall(send_msg.encode('utf-8'))
                    
                    suppression_counter = SUPPRESSION_PULL_DOWN
                else:
                    msg = f"  ({prediction}: {top_score*100:.1f}%, ë³¼ë¥¨: {volume:.2f})"
                    print(msg.ljust(50), end='\r', flush=True)

    except ConnectionResetError:
        print(f"âš ï¸ í´ë¼ì´ì–¸íŠ¸({addr}) ë¹„ì •ìƒ ì¢…ë£Œ")
    finally:
        client_socket.close()
