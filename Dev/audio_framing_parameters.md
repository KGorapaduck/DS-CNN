# KWS 오디오 프레이밍 파라미터 (Window Size & Stride) 설명

본 문서는 오디오 신호를 딥러닝 모델이 이해할 수 있는 벡터(MFCC 등)로 변환하는 '프레이밍(Framing)' 과정의 핵심 파라미터인 `WINDOW_SIZE_MS`와 `WINDOW_STRIDE_MS`에 대해 설명합니다.

## 1. 개요
오디오 데이터는 실시간으로 변하는 연속적인 신호입니다. 딥러닝 모델이 이를 처리하기 위해서는 신호를 아주 짧은 시간 단위로 쪼개어 각 조각의 주파수 특징을 추출해야 합니다.

## 2. 주요 파라미터 정의

### 2.1 WINDOW_SIZE_MS (창 크기) - 예: 40.0ms
- **정의**: 한 번에 주파수 분석(FFT 등)을 수행하기 위해 바라보는 **시간의 폭**입니다.
- **역할**: 이 시간 동안 소리는 변하지 않는다고 가정(Stationary)하고 분석을 진행합니다.
- **영향**: 
    - 값이 너무 짧으면: 주파수 해상도가 떨어져 소리의 높낮이를 정확히 구분하기 어렵습니다.
    - 값이 너무 길면: 소리의 빠른 변화를 평균화하여 섬세한 음운 변화를 놓칠 수 있습니다.

### 2.2 WINDOW_STRIDE_MS (이동 간격 / 보폭) - 예: 20.0ms
- **정의**: 다음 분석창을 만들기 위해 시간축 상에서 **얼마나 옆으로 이동할 것인가**를 나타냅니다.
- **역할**: 분석의 조밀도(Density)를 결정합니다.
- **Overlap(겹침)**: 만약 `WINDOW_SIZE`가 40ms이고 `STRIDE`가 20ms라면, 20ms만큼 겹치면서 데이터를 분석하게 됩니다(50% Overlap). 데이터 간의 연속성을 보장하기 위해 보통 50% 이상의 겹침을 유지합니다.

---

## 3. 시각적 개념도
```text
[ Window 1 (40ms) ]
          [ Window 2 (40ms) ]
                    [ Window 3 (40ms) ]
|----------|----------|----------|----------|
0ms       20ms       40ms       60ms       80ms
     (Stride=20ms)
```

## 4. 모델 성능에 미치는 영향

- **포착 정밀도**: Stride가 작을수록 데이터를 더 촘촘하게 스캔하므로 인식 모델이 특정 키워드(예: '퀴즈')의 시작과 끝을 더 정확히 포착할 수 있습니다. 단, 계산량과 메모리 사용량이 늘어납니다.
- **입력 데이터 형태(Input Shape)**: 
    - 1초(1,000ms) 데이터를 20ms 간격으로 쪼개면 총 50개의 시간 단계(Time Step)를 갖는 특징 맵이 생성됩니다.
    - 이 값은 신경망 모델의 첫 번째 레이어 입력 크기를 결정하므로, **이 값을 수정하면 반드시 모델 학습(`train.py`)부터 다시 수행해야 합니다.**

## 5. 결론
현재 프로젝트에서 설정된 40ms/20ms 값은 임베디드 장치(라즈베리파이 등)의 연산 대역폭과 키워드 인식의 정확도 사이에서 최적화된 표준값입니다. 인식률 개선을 위해서는 이 파라미터 자체를 건드리기보다, 모델 뒷단의 판정 임계값(Threshold)이나 스무딩 로직을 먼저 조정하는 것이 권장됩니다.
